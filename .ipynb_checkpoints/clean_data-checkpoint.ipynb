{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import set_option\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "\n",
    "def drop_exclude_cols(df, exclude_cols):\n",
    "    \n",
    "    exclude_cols = \"|\".join(exclude_cols)\n",
    "    \n",
    "    df.drop(df.filter(regex = exclude_cols, axis = 1).columns,\n",
    "            axis = 1,\n",
    "            inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def tidy_columns(df):\n",
    "    \n",
    "    # Tidy column to keep\n",
    "    df.columns = df.columns.str.replace(\" \", \"_\").str.lower()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_na_values(df, na_to_clean = list):\n",
    "    \n",
    "    # Assign NA values\n",
    "    for na in na_to_clean:\n",
    "        \n",
    "        df = df.replace(na, np.nan)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def save_cleaned_csv(df, csv_path: str):\n",
    "    \n",
    "    df.to_csv(f\"{csv_path.split('.')[0]}_cleaned.csv\", \n",
    "              index = False)\n",
    "    \n",
    "    \n",
    "def format_bool_to_int(df,convert_additional_cols):\n",
    "\n",
    "    for c in df.select_dtypes(include='bool').columns:\n",
    "        df[c] = df[c].fillna(3)\n",
    "        df[c] = df[c].astype(int)\n",
    "\n",
    "    if convert_additional_cols:\n",
    "        for c in convert_additional_cols:\n",
    "            df[c] = df[c].fillna(3)\n",
    "            df[c] = df[c].astype(int)\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "def format_hospital_comparisons_cols(df):\n",
    "    \n",
    "    comparison_dict = {\n",
    "    'Below the National average': 1, \n",
    "    'Same as the National average': 2, \n",
    "    'Above the National average':3 }\n",
    "    \n",
    "    df = df.replace(comparison_dict)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def pivot_readmission_types(df_in):\n",
    "    \n",
    "    agg_cols = [\"number_of_readmissions\", \n",
    "                \"number_of_discharges\", \n",
    "                \"excess_readmission_ratio\",\n",
    "                \"predicted_readmission_rate\",\n",
    "                \"expected_readmission_rate\"]\n",
    "    \n",
    "    df_agg = df_in.loc[:,[\"provider_number\"]].drop_duplicates()\n",
    "\n",
    "    for col in agg_cols:\n",
    "        df_temp = pd.pivot_table(data = df_in, \n",
    "             index=['provider_number'],\n",
    "             columns = [\"measure_name\"],\n",
    "             values= col,\n",
    "            aggfunc = np.sum).reset_index()\n",
    "        \n",
    "        update_cols = \\\n",
    "        [\"provider_number\"] + \\\n",
    "        [f\"{c.lower().replace('-', '_')}_{col}\" \\\n",
    "        for c in df_temp.columns if \"provider_number\" not in c]\n",
    "         \n",
    "        df_temp.columns = update_cols\n",
    "         \n",
    "        df_agg = pd.merge(df_agg, df_temp, on = \"provider_number\", how = \"inner\")\n",
    "         \n",
    "    df_in.drop(agg_cols + [\"measure_name\"], axis = 1, inplace = True)\n",
    "    df_out = pd.merge(df_in, df_agg, on = \"provider_number\", how = \"inner\"). \\\n",
    "         drop_duplicates([\"provider_number\"])\n",
    "    \n",
    "    df_out.replace({\"Too Few to Report\":0}, inplace = True)\n",
    "\n",
    "    return df_out \n",
    "         \n",
    "\n",
    "def remove_all_cleaned_files(directory_path: str):\n",
    "    \n",
    "    cleaned_files = [f for f in os.listdir(directory_path) if \"_cleaned\" in f]\n",
    "\n",
    "    for f in cleaned_files:\n",
    "        os.remove(f)\n",
    "\n",
    "\n",
    "def bin_states_to_region(directory_path: str):\n",
    "\n",
    "    # Time zone dictionary \n",
    "    state_to_region = { 'AK': 'US/Alaska', 'AL': 'US/Central',\n",
    "                       'AR': 'US/Central', 'AS': 'US/Samoa',\n",
    "                       'AZ': 'US/Mountain', 'CA': 'US/Pacific', \n",
    "                       'CO': 'US/Mountain', 'CT': 'US/Eastern',\n",
    "                       'DC': 'US/Eastern', 'DE': 'US/Eastern', \n",
    "                       'FL': 'US/Eastern', 'GA': 'US/Eastern',\n",
    "                       'GU': 'Pacific/Guam', 'HI': 'US/Hawaii',\n",
    "                       'IA': 'US/Central', 'ID': 'US/Mountain',\n",
    "                       'IL': 'US/Central', 'IN': 'US/Eastern', \n",
    "                       'KS': 'US/Central', 'KY': 'US/Eastern', \n",
    "                       'LA': 'US/Central', 'MA': 'US/Eastern', \n",
    "                       'MD': 'US/Eastern', 'ME': 'US/Eastern', \n",
    "                       'MI': 'US/Eastern', 'MN': 'US/Central',\n",
    "                       'MO': 'US/Central', 'MP': 'Pacific/Guam', \n",
    "                       'MS': 'US/Central', 'MT': 'US/Mountain',\n",
    "                       'NC': 'US/Eastern', 'ND': 'US/Central', \n",
    "                       'NE': 'US/Central', 'NH': 'US/Eastern',\n",
    "                       'NJ': 'US/Eastern', 'NM': 'US/Mountain',\n",
    "                       'NV': 'US/Pacific', 'NY': 'US/Eastern', \n",
    "                       'OH': 'US/Eastern', 'OK': 'US/Central', \n",
    "                       'OR': 'US/Pacific', 'PA': 'US/Eastern', \n",
    "                       'PR': 'America/Puerto_Rico', 'RI': 'US/Eastern', \n",
    "                       'SC': 'US/Eastern','SD': 'US/Central', \n",
    "                       'TN': 'US/Central', 'TX': 'US/Central', \n",
    "                       'UT': 'US/Mountain', 'VA': 'US/Eastern', \n",
    "                       'VI': 'America/Virgin','VT': 'US/Eastern', \n",
    "                       'WA': 'US/Pacific', 'WI': 'US/Central', \n",
    "                       'WV': 'US/Eastern',  'WY': 'US/Mountain', \n",
    "                       '' : 'US/Pacific',  '--': 'US/Pacific' }\n",
    "    \n",
    "    state_to_region_df = pd.DataFrame(state_to_region.items())\n",
    "    state_to_region_df.columns = ['state', 'region']\n",
    "\n",
    "    # Merge time zones with dataframe and clean data types\n",
    "    df = pd.read_csv(directory_path)\n",
    "    \n",
    "    df = pd.merge(left = df ,\n",
    "                  right = state_to_region_df,\n",
    "                  how = 'left',\n",
    "                  on = 'state')\n",
    "\n",
    "    # Save cleaned csv\n",
    "    df.to_csv('med_data_merged_geo.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_all_cleaned_files(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_general_info(csv_path: str,\n",
    "                      exclude_cols: list,\n",
    "                      na_to_clean: list,\n",
    "                      convert_additional_cols: list):\n",
    "    # Import csv\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    df = tidy_columns(df)\n",
    "    \n",
    "    df = drop_exclude_cols(df,exclude_cols)\n",
    "    \n",
    "    # Assign NA values\n",
    "    df = clean_na_values(df, na_to_clean)\n",
    "    \n",
    "    df = format_bool_to_int(df, convert_additional_cols)\n",
    "    \n",
    "    df = format_hospital_comparisons_cols(df)\n",
    "    \n",
    "    # Save cleaned csv\n",
    "    save_cleaned_csv(df, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_general_info(csv_path: str,\n",
    "                      exclude_cols: list,\n",
    "                      na_to_clean: list,\n",
    "                      convert_additional_cols: list):\n",
    "    # Import csv\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    df = tidy_columns(df)\n",
    "    \n",
    "    df = drop_exclude_cols(df,exclude_cols)\n",
    "    \n",
    "    # Assign NA values\n",
    "    df = clean_na_values(df, na_to_clean)\n",
    "    \n",
    "    df = format_bool_to_int(df, convert_additional_cols)\n",
    "    \n",
    "    df = format_hospital_comparisons_cols(df)\n",
    "    \n",
    "    # Save cleaned csv\n",
    "    save_cleaned_csv(df, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mspb_info(csv_path: str,\n",
    "                      exclude_cols: [],\n",
    "                      na_to_clean: []):\n",
    "    \n",
    "    # Import csv\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    df = tidy_columns(df)\n",
    "    \n",
    "    df = drop_exclude_cols(df,exclude_cols)\n",
    "    \n",
    "    # Assign NA values\n",
    "    df = clean_na_values(df, na_to_clean)\n",
    "        \n",
    "    # Save cleaned csv\n",
    "    save_cleaned_csv(df, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_readmissions_info(csv_path: str,\n",
    "                            exclude_cols: list,\n",
    "                           na_to_clean = list):\n",
    "    # Import csv\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    df = tidy_columns(df)\n",
    "    \n",
    "    df = drop_exclude_cols(df,exclude_cols)\n",
    "    \n",
    "    # pivot and aggregatate readmissions data by clinical area\n",
    "    df = pivot_readmission_types(df)\n",
    "    \n",
    "    # Assign NA values\n",
    "    df = clean_na_values(df, na_to_clean)\n",
    "    \n",
    "    # Save cleaned csv\n",
    "    save_cleaned_csv(df,csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_clean_tables(directory_path: str):\n",
    "    \n",
    "    cleaned_files = [f for f in os.listdir(directory_path) if \"_cleaned\" in f]\n",
    "    df = pd.read_csv(cleaned_files[0])\n",
    "\n",
    "    for table in cleaned_files[1:]:\n",
    "        table = pd.read_csv(table)\n",
    "        table.rename(columns ={\"provider_number\":\"provider_id\"}, inplace = True)\n",
    "        df = pd.merge(df, table, on = \"provider_id\", how = \"outer\")\n",
    "    \n",
    "    df.to_csv(\"med_data_merged.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_general_info(\"Hospital_General_Information.csv\", \n",
    "                  exclude_cols = [\"footnote\",\n",
    "                                  \"measure_id\",\n",
    "                                  \"start_date\",\n",
    "                                  \"end_date\",\n",
    "                                  \"hospital_name\",\n",
    "                                  \"zip_code\",\n",
    "                                  \"location\", \n",
    "                                  \"address\",\n",
    "                                  \"phone_number\",\n",
    "                                  \"city\",\n",
    "                                 \"county_name\"],\n",
    "                  na_to_clean = [\"Not Available\"],\n",
    "                  convert_additional_cols = \\\n",
    "                   [\"meets_criteria_for_meaningful_use_of_ehrs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_mspb_info(\"Medicare_hospital_spending_per_patient__\" \\\n",
    "                     \"Medicare_Spending_per_Beneficiary____Additional_Decimal_Places.csv\", \n",
    "                    exclude_cols = [\"footnote\",\n",
    "                                    \"location\",\n",
    "                                    \"measure_id\",\n",
    "                                    \"start_date\",\n",
    "                                    \"end_date\",],\n",
    "                na_to_clean = [\"Not Available\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_readmissions_info(\"Hospital_Readmissions_Reduction_Program.csv\",\n",
    "                       exclude_cols = [\"footnote\",\n",
    "                                       \"start_date\",\n",
    "                                       \"end_date\",\n",
    "                                       \"hospital_name\", \n",
    "                                       \"state\",\n",
    "                                       \"region\"],\n",
    "                       na_to_clean = [\"Not Available\", \"Too Few to Report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_clean_tables(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_states_to_region(\"med_data_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"med_data_merged_geo.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
